{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "starter_notbook_dl__v1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bouzayeniiheb/UmojaHack-Tunisia-InstaDeep-Kinase-Classification-Challenge-by-UmojaHack-Africa/blob/main/final_sub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnwJhWNL_0sE"
      },
      "source": [
        "\n",
        "\n",
        "# **UmojaHack Tunisia: InstaDeep Kinase Classification Challenge by UmojaHack Africa** \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This hackathon was a great opportunity to develop our skills more and more.The goal of this competition is to build a model that assigns a kinase type (as defined by Enzyme Commission number) to an arbitrary sequence of amino acids. All the sequences in both training and test dataset are complete sequences of protein kinases. Each comprises up to 560 positions, and each position can take one of 20 values (there are 20 standard amino acids produced in eukaryotic cells).\n",
        "\n",
        "As each letter in an amino acid sequence represents a physical structure (one amino acid), these sequences can be augmented by converting each letter into a numerical representation of that amino acid. There are several ways to do this:\n",
        "\n",
        "Our Solution is an ensemble of 7 DL models! \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlmCyqGaVTHp"
      },
      "source": [
        "import pandas as  pd \n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" # change it to \"0\" if yo have only one gpu or the gpu numbe  that you would like to use "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx3oiaaOVgF1",
        "outputId": "29921b0b-b60b-4065-dd47-dc18ca13a9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEmxwgNoVTHs"
      },
      "source": [
        "### Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0hHVCv2VTHt"
      },
      "source": [
        "def write_to_txt(file_name,column):\n",
        "    with open(file_name, 'w') as f:\n",
        "        for item in column:\n",
        "            f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23rabhllVTHx"
      },
      "source": [
        "train=pd.read_csv(\"/content/drive/My Drive/UmojaHackTunisia/UmojaHackTun/train.csv\")\n",
        "test=pd.read_csv(\"/content/drive/My Drive/UmojaHackTunisia/UmojaHackTun/test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23edY-RlVTHz",
        "outputId": "45f8c84d-690c-43ed-9692-938049dcb972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_train_0</td>\n",
              "      <td>MVDGVMILPVLVMIAFPFPSMEDEKPKVNPKLYMCVCEGLSCGDEA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_train_1</td>\n",
              "      <td>MAQKENAYPWPYGSKTSQSGLNTLSQRVLRKEPATTSALALVNRFN...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_train_2</td>\n",
              "      <td>MRLWPRSLFGRLVLILVSGMLAAQILTSSIWYDVRHSQVLEIPTRL...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_train_3</td>\n",
              "      <td>MNSIVKIMKMKQITYKLFMTTSLILLSFAVLIYLTLYFFLPTFYEQ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_train_4</td>\n",
              "      <td>MKLIYQNVLSFLLIIVTTISIIGYSEIGYARNQAYTQNYQRMESYA...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID                                           Sequence  target\n",
              "0  ID_train_0  MVDGVMILPVLVMIAFPFPSMEDEKPKVNPKLYMCVCEGLSCGDEA...       0\n",
              "1  ID_train_1  MAQKENAYPWPYGSKTSQSGLNTLSQRVLRKEPATTSALALVNRFN...       1\n",
              "2  ID_train_2  MRLWPRSLFGRLVLILVSGMLAAQILTSSIWYDVRHSQVLEIPTRL...       2\n",
              "3  ID_train_3  MNSIVKIMKMKQITYKLFMTTSLILLSFAVLIYLTLYFFLPTFYEQ...       2\n",
              "4  ID_train_4  MKLIYQNVLSFLLIIVTTISIIGYSEIGYARNQAYTQNYQRMESYA...       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nra-RyYLVTH2"
      },
      "source": [
        "max_seq_length=550# max seq length in this data set is 550 "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDo7Eqn9VTH4"
      },
      "source": [
        "# split data to train and validation \n",
        "train,val=train_test_split(train,test_size=0.1,random_state=1994)\n",
        "\n",
        "#reduce seq length\n",
        "if max_seq_length>550 : \n",
        "    train[\"Sequence\"]=train[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))\n",
        "    val[\"Sequence\"]=val[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))\n",
        "    test[\"Sequence\"]=test[\"Sequence\"].apply(lambda x: \"\".join(list(x)[0:max_seq_length]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0YgVuvmVTH7"
      },
      "source": [
        "# # write Sequnce column to txt file \n",
        "write_to_txt(\"/content/train.txt\",train.Sequence)\n",
        "write_to_txt(\"/content/test.txt\",test.Sequence)\n",
        "write_to_txt(\"/content/val.txt\",val.Sequence)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8utKh2ULVTH-"
      },
      "source": [
        "train_label=train[[\"target\"]].copy()\n",
        "val_label=val[[\"target\"]].copy()\n",
        "train_label.to_csv(\"/content/train_label.csv\",index=False)\n",
        "val_label.to_csv(\"/content/val_label.csv\",index=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgPDzlg7VTIB"
      },
      "source": [
        "### Data loaders "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxV6T_RvVTIB"
      },
      "source": [
        "train_label=pd.read_csv(\"/content/train_label.csv\")\n",
        "val_label=pd.read_csv(\"/content/val_label.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mngwsR-mVTID"
      },
      "source": [
        "train_batch_size=512\n",
        "val_batch_size=512\n",
        "number_of_class=train_label.target.nunique()\n",
        "train_steps = len(train_label) // train_batch_size + int(len(train_label) % train_batch_size > 0)\n",
        "val_steps = len(val_label) // val_batch_size + int(len(val_label) % val_batch_size > 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0x-0yjcVTIG"
      },
      "source": [
        "voc_set=set(['P', 'V', 'I', 'K', 'N', 'B', 'F', 'Y', 'E', 'W', 'R', 'D', 'X', 'S', 'C', 'U', 'Q', 'A', 'M', 'H', 'L', 'G', 'T'])\n",
        "voc_set_map={ k:v for k , v in zip(voc_set,range(1,len(voc_set)+1))}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4RkfEZxVTIJ"
      },
      "source": [
        "def encode(text_tensor, label):\n",
        "    encoded_text = [ voc_set_map[e] for e in list(text_tensor.numpy().decode())]\n",
        "    return encoded_text, label\n",
        "def encode_map_fn(text, label):\n",
        "    # py_func doesn't set the shape of the returned tensors.\n",
        "    encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "    encoded_text.set_shape([None])\n",
        "    label=tf.one_hot(label,number_of_class)\n",
        "    label.set_shape([number_of_class])\n",
        "    \n",
        "    return encoded_text, label\n",
        "def get_data_loader(file,batch_size,labels):\n",
        "    \n",
        "    label_data=tf.data.Dataset.from_tensor_slices(labels.target)\n",
        "    data_set=tf.data.TextLineDataset(file)\n",
        "    data_set=tf.data.Dataset.zip((data_set,label_data))\n",
        "\n",
        "    data_set=data_set.repeat()\n",
        "    data_set = data_set.shuffle(len(labels))\n",
        "    data_set=data_set.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
        "    data_set=data_set.padded_batch(batch_size)\n",
        "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return data_set\n",
        "\n",
        "\n",
        "def get_data_loader_test(file,batch_size,labels):\n",
        "    \n",
        "    label_data=tf.data.Dataset.from_tensor_slices(labels.target)\n",
        "    data_set=tf.data.TextLineDataset(file)\n",
        "    data_set=tf.data.Dataset.zip((data_set,label_data))\n",
        "    data_set=data_set.map(encode_map_fn,tf.data.experimental.AUTOTUNE)\n",
        "    data_set=data_set.padded_batch(batch_size)\n",
        "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return data_set"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niZ1F5DvVTIL"
      },
      "source": [
        "train_dl=get_data_loader(\"/content/train.txt\",train_batch_size,train_label)\n",
        "val_dl=get_data_loader(\"/content/val.txt\",train_batch_size,val_label)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YhMaEzSVTIO"
      },
      "source": [
        "### Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJwxQnn1VTIO"
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Dropout,Embedding,Concatenate,Flatten,LSTM ,Bidirectional\n",
        "from tensorflow.keras.activations import relu ,sigmoid,softmax\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "def model():\n",
        "    name=\"seq\"\n",
        "    dropout_rate=0.1\n",
        "    learning_rate=0.001\n",
        "    sequnce=Input([None],name=\"sequnce\")\n",
        "    \n",
        "    EMB_layer=Embedding(input_dim=len(voc_set)+1,output_dim=64,name=\"emb_layer\")\n",
        "    \n",
        "\n",
        "    LSTM_layer_2=LSTM(units=256,name=\"lstm_2\",return_sequences=False)\n",
        "    BIDIR_layer_2=Bidirectional(LSTM_layer_2,name=\"bidirectional_2\")\n",
        "    \n",
        "    Dens_layer_1=Dense(units=512,activation=relu,kernel_regularizer=None,bias_regularizer=None,name=name+\"_dense_layer_1\")\n",
        "    Dens_layer_2=Dense(units=256,activation=relu,kernel_regularizer=None,bias_regularizer=None,name=name+\"_dense_layer_2\")\n",
        "    \n",
        "    output=Dense(units=number_of_class,activation=softmax,kernel_regularizer=None,bias_regularizer=None,name=name+\"_dense_layer_output\")\n",
        "    \n",
        "    dropout_1=Dropout(dropout_rate)\n",
        "    \n",
        "    \n",
        "    emb_layer=EMB_layer(sequnce)\n",
        "    logits=output(Dens_layer_2(dropout_1(Dens_layer_1(BIDIR_layer_2(emb_layer)))))\n",
        "\n",
        "    \n",
        "    model=tf.keras.Model(inputs={\"sequnce\":sequnce, },outputs=logits) \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"Acc\")]) \n",
        "    model.summary()\n",
        "    return model \n",
        "    "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvSotNkvVTIQ",
        "outputId": "e1713393-8ec1-472b-fdeb-c8cd14ed5a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model=model()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequnce (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "emb_layer (Embedding)        (None, None, 64)          1536      \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 512)               657408    \n",
            "_________________________________________________________________\n",
            "seq_dense_layer_1 (Dense)    (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "seq_dense_layer_2 (Dense)    (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "seq_dense_layer_output (Dens (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 1,054,984\n",
            "Trainable params: 1,054,984\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFtdichOVTIT"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "nfQnrDPOVTIV",
        "outputId": "699da606-1bac-4261-c555-9f08eb5aedfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history = model.fit(train_dl,\n",
        "                    validation_data=val_dl,\n",
        "                    epochs=#to be defined,\n",
        "                    verbose=1,\n",
        "                    validation_steps=val_steps,\n",
        "                    steps_per_epoch=train_steps\n",
        "                   )"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 445s 557ms/step - loss: 0.0044 - Acc: 0.9986 - val_loss: 0.0151 - val_Acc: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkHNuTF5VTIY"
      },
      "source": [
        "def encode_test(text_tensor):\n",
        "    encoded_text = [ voc_set_map[e] for e in list(text_tensor.numpy().decode())]\n",
        "    return (encoded_text)\n",
        "def encode_map_fn_test(text):\n",
        "    # py_func doesn't set the shape of the returned tensors.\n",
        "    encoded_text = tf.py_function(encode_test, \n",
        "                                       inp=[text], \n",
        "                                       Tout=tf.int64)\n",
        "    encoded_text.set_shape([None])\n",
        "\n",
        "    \n",
        "    return (encoded_text)\n",
        "\n",
        "def get_test_data_loader(file,batch_size):\n",
        "    data_set=tf.data.TextLineDataset(file)\n",
        "    data_set=data_set.map(encode_map_fn_test,tf.data.experimental.AUTOTUNE)\n",
        "    data_set=data_set.padded_batch(batch_size)\n",
        "    data_set = data_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return data_set"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JXO_Kr4VTIa",
        "outputId": "4ca213b7-4b41-4261-cb47-cceffcb2db5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "  test=pd.read_csv(\"/content/drive/My Drive/UmojaHackTunisia/UmojaHackTun/test.csv\")\n",
        "  test[\"target\"]=0\n",
        "  test_dl=get_data_loader_test(\"/content/test.txt\",512,test)\n",
        "  test_pred=model.predict(test_dl,verbose=True)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "222/222 [==============================] - 55s 247ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKwSd0shVTId"
      },
      "source": [
        "sub=test[[\"ID\"]].copy()\n",
        "for i in range(number_of_class):\n",
        "    sub[\"target_{}\".format(i)]=test_pred[:,i]"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWlSH-nWVTIg"
      },
      "source": [
        "sub.to_csv(\"sub.csv\",index=False)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyk6IeuEVTIj"
      },
      "source": [
        "df1=pd.read_csv('/content/sub_15epoch_lr0.001.csv')\n",
        "df2=pd.read_csv('/content/sub_20epoch_lr0.001.csv')\n",
        "df3=pd.read_csv('/content/sub_25epoch_lr0.001.csv')\n",
        "df4=pd.read_csv('/content/sub_28epoch_lr0.001.csv')\n",
        "df5=pd.read_csv('/content/sub_29epoch_lr0.001.csv')\n",
        "df6=pd.read_csv('/content/sub_40epoch_lr0.001.csv')\n",
        "df7=pd.read_csv('/content/sub_43epoch_lr0.001.csv')\n",
        "\n"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbNCp-14JUUa"
      },
      "source": [
        "df1=df1.drop(['ID'],axis=1)\n",
        "df2=df2.drop(['ID'],axis=1)\n",
        "df3=df3.drop(['ID'],axis=1)\n",
        "df4=df4.drop(['ID'],axis=1)\n",
        "df5=df5.drop(['ID'],axis=1)\n",
        "df6=df6.drop(['ID'],axis=1)\n",
        "df7=df7.drop(['ID'],axis=1)\n",
        "\n"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FULf1Vj1JiKK",
        "outputId": "dc088a2c-a556-4a4a-e40c-5b7dfa7805a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "sum=(df1+df2+df3+df4+df5+df6+df7)/7\n",
        "sum.head()"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_0</th>\n",
              "      <th>target_1</th>\n",
              "      <th>target_2</th>\n",
              "      <th>target_3</th>\n",
              "      <th>target_4</th>\n",
              "      <th>target_5</th>\n",
              "      <th>target_6</th>\n",
              "      <th>target_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.743778e-09</td>\n",
              "      <td>6.167194e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>1.563821e-08</td>\n",
              "      <td>2.751316e-10</td>\n",
              "      <td>1.209903e-12</td>\n",
              "      <td>1.622911e-12</td>\n",
              "      <td>5.024944e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.631812e-09</td>\n",
              "      <td>8.330158e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>2.671227e-08</td>\n",
              "      <td>2.675956e-10</td>\n",
              "      <td>1.790893e-12</td>\n",
              "      <td>1.584419e-12</td>\n",
              "      <td>1.188894e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.817937e-07</td>\n",
              "      <td>1.190297e-04</td>\n",
              "      <td>0.999877</td>\n",
              "      <td>3.059235e-06</td>\n",
              "      <td>2.719024e-08</td>\n",
              "      <td>5.503442e-11</td>\n",
              "      <td>2.030765e-10</td>\n",
              "      <td>1.144229e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.698230e-09</td>\n",
              "      <td>9.452509e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>5.241113e-08</td>\n",
              "      <td>9.162993e-10</td>\n",
              "      <td>7.782105e-12</td>\n",
              "      <td>2.914901e-12</td>\n",
              "      <td>1.210879e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.181092e-04</td>\n",
              "      <td>9.816592e-01</td>\n",
              "      <td>0.002884</td>\n",
              "      <td>1.088480e-02</td>\n",
              "      <td>7.189217e-08</td>\n",
              "      <td>1.941844e-05</td>\n",
              "      <td>3.881604e-04</td>\n",
              "      <td>3.245914e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       target_0      target_1  ...      target_6      target_7\n",
              "0  2.743778e-09  6.167194e-07  ...  1.622911e-12  5.024944e-11\n",
              "1  5.631812e-09  8.330158e-07  ...  1.584419e-12  1.188894e-10\n",
              "2  4.817937e-07  1.190297e-04  ...  2.030765e-10  1.144229e-09\n",
              "3  3.698230e-09  9.452509e-07  ...  2.914901e-12  1.210879e-10\n",
              "4  9.181092e-04  9.816592e-01  ...  3.881604e-04  3.245914e-03\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPp0TCJOJqpn"
      },
      "source": [
        "sum.insert(0,'ID',sub['ID'])"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H32824jCLEsZ",
        "outputId": "ca49b58d-0d81-47b0-97b9-d339e680505f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "sum.head()"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>target_0</th>\n",
              "      <th>target_1</th>\n",
              "      <th>target_2</th>\n",
              "      <th>target_3</th>\n",
              "      <th>target_4</th>\n",
              "      <th>target_5</th>\n",
              "      <th>target_6</th>\n",
              "      <th>target_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_test_0</td>\n",
              "      <td>2.743778e-09</td>\n",
              "      <td>6.167194e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>1.563821e-08</td>\n",
              "      <td>2.751316e-10</td>\n",
              "      <td>1.209903e-12</td>\n",
              "      <td>1.622911e-12</td>\n",
              "      <td>5.024944e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_test_1</td>\n",
              "      <td>5.631812e-09</td>\n",
              "      <td>8.330158e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>2.671227e-08</td>\n",
              "      <td>2.675956e-10</td>\n",
              "      <td>1.790893e-12</td>\n",
              "      <td>1.584419e-12</td>\n",
              "      <td>1.188894e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_test_2</td>\n",
              "      <td>4.817937e-07</td>\n",
              "      <td>1.190297e-04</td>\n",
              "      <td>0.999877</td>\n",
              "      <td>3.059235e-06</td>\n",
              "      <td>2.719024e-08</td>\n",
              "      <td>5.503442e-11</td>\n",
              "      <td>2.030765e-10</td>\n",
              "      <td>1.144229e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_test_3</td>\n",
              "      <td>3.698230e-09</td>\n",
              "      <td>9.452509e-07</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>5.241113e-08</td>\n",
              "      <td>9.162993e-10</td>\n",
              "      <td>7.782105e-12</td>\n",
              "      <td>2.914901e-12</td>\n",
              "      <td>1.210879e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_test_4</td>\n",
              "      <td>9.181092e-04</td>\n",
              "      <td>9.816592e-01</td>\n",
              "      <td>0.002884</td>\n",
              "      <td>1.088480e-02</td>\n",
              "      <td>7.189217e-08</td>\n",
              "      <td>1.941844e-05</td>\n",
              "      <td>3.881604e-04</td>\n",
              "      <td>3.245914e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID      target_0  ...      target_6      target_7\n",
              "0  ID_test_0  2.743778e-09  ...  1.622911e-12  5.024944e-11\n",
              "1  ID_test_1  5.631812e-09  ...  1.584419e-12  1.188894e-10\n",
              "2  ID_test_2  4.817937e-07  ...  2.030765e-10  1.144229e-09\n",
              "3  ID_test_3  3.698230e-09  ...  2.914901e-12  1.210879e-10\n",
              "4  ID_test_4  9.181092e-04  ...  3.881604e-04  3.245914e-03\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlXmHWggJpZA"
      },
      "source": [
        "sum.to_csv(\"final_sub.csv\",index=False)"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v89NqMAPpeiL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}